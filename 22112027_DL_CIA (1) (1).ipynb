{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b895675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrut\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\shrut\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\shrut\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\shrut\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.0)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f2db2a-500d-4536-8455-95ce479d5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "DATA_PATH = 'Audio_Files/'  # Update this with your path\n",
    "major_folder = os.path.join(DATA_PATH, 'major')\n",
    "minor_folder = os.path.join(DATA_PATH, 'minor')\n",
    "\n",
    "# Hyperparameters\n",
    "n_mfcc = 20  \n",
    "sequence_length = 30  \n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ec154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess audio files\n",
    "def load_and_extract_features(folder_path):\n",
    "    features = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            y, sr = librosa.load(file_path)\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "            features.append(mfccs.T)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3454ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "major_features = load_and_extract_features(major_folder)\n",
    "minor_features = load_and_extract_features(minor_folder)\n",
    "\n",
    "# Prepare sequences\n",
    "def create_sequences(features, seq_length):\n",
    "    X, y = [], []\n",
    "    for mfcc in features:\n",
    "        for i in range(len(mfcc) - seq_length):\n",
    "            X.append(mfcc[i:i + seq_length])\n",
    "            y.append(mfcc[i + seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c079e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_major, y_major = create_sequences(major_features, sequence_length)\n",
    "X_minor, y_minor = create_sequences(minor_features, sequence_length)\n",
    "\n",
    "# Combine and label data (1 for major, 0 for minor)\n",
    "X = np.concatenate((X_major, X_minor), axis=0)\n",
    "y = np.concatenate((y_major, y_minor), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d452d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrut\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(sequence_length, n_mfcc), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(n_mfcc)  # Output layer with the same dimension as MFCC input\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e577b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,760</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m21,760\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,524</span> (224.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,524\u001b[0m (224.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,524</span> (224.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,524\u001b[0m (224.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 41ms/step - loss: 4055.2861 - val_loss: 606.1160\n",
      "Epoch 2/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 40ms/step - loss: 490.6552 - val_loss: 143.1201\n",
      "Epoch 3/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - loss: 192.3761 - val_loss: 109.3244\n",
      "Epoch 4/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - loss: 165.5600 - val_loss: 100.6715\n",
      "Epoch 5/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - loss: 155.7856 - val_loss: 97.2126\n",
      "Epoch 6/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 34ms/step - loss: 150.0359 - val_loss: 96.6808\n",
      "Epoch 7/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 34ms/step - loss: 146.2354 - val_loss: 92.5811\n",
      "Epoch 8/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - loss: 142.7170 - val_loss: 89.9662\n",
      "Epoch 9/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - loss: 138.0513 - val_loss: 87.4177\n",
      "Epoch 10/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 134.7647 - val_loss: 87.6687\n",
      "Epoch 11/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 129.9500 - val_loss: 83.6419\n",
      "Epoch 12/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - loss: 130.1402 - val_loss: 79.7878\n",
      "Epoch 13/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - loss: 122.5917 - val_loss: 81.1944\n",
      "Epoch 14/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - loss: 120.8897 - val_loss: 77.4183\n",
      "Epoch 15/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - loss: 118.4245 - val_loss: 75.8484\n",
      "Epoch 16/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - loss: 114.2781 - val_loss: 75.6577\n",
      "Epoch 17/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 112.3637 - val_loss: 73.7750\n",
      "Epoch 18/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - loss: 108.2301 - val_loss: 71.2567\n",
      "Epoch 19/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40ms/step - loss: 104.5000 - val_loss: 72.1390\n",
      "Epoch 20/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 45ms/step - loss: 100.4783 - val_loss: 67.2329\n",
      "Epoch 21/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 86ms/step - loss: 95.1257 - val_loss: 62.8173\n",
      "Epoch 22/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 91ms/step - loss: 90.4192 - val_loss: 59.2195\n",
      "Epoch 23/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 88ms/step - loss: 85.2510 - val_loss: 59.1313\n",
      "Epoch 24/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 76ms/step - loss: 80.3584 - val_loss: 53.4864\n",
      "Epoch 25/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 49ms/step - loss: 75.3179 - val_loss: 51.2329\n",
      "Epoch 26/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - loss: 70.8768 - val_loss: 49.9078\n",
      "Epoch 27/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - loss: 67.9127 - val_loss: 47.8595\n",
      "Epoch 28/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 61ms/step - loss: 65.4084 - val_loss: 46.7697\n",
      "Epoch 29/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 78ms/step - loss: 61.8384 - val_loss: 45.6907\n",
      "Epoch 30/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 84ms/step - loss: 60.6193 - val_loss: 43.2519\n",
      "Epoch 31/50\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 78ms/step - loss: 57.6541 - val_loss: 41.1966\n",
      "Epoch 32/50\n",
      "\u001b[1m1123/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 56.9426"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (MSE): {test_loss}\")\n",
    "\n",
    "# Save model \n",
    "model.save(\"melody_generator_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef43605-e822-42d5-8ee2-3e290f8e6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss (MSE) on the training data\n",
    "train_loss = model.evaluate(X_train, y_train)\n",
    "print(f\"Training Loss (MSE): {train_loss}\")\n",
    "\n",
    "# Calculate test loss (MSE) on the test data\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (MSE): {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788aaf3-efb5-46c6-bdbc-7a2cab61abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared score for training and test sets\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R^2 Score: {train_r2}\")\n",
    "print(f\"Test R^2 Score: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1a75d-9469-4fce-98f3-d4096fe6ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate a sequence\n",
    "def generate_sequence(model, start_sequence, sequence_length):\n",
    "    generated_sequence = start_sequence.copy()\n",
    "    \n",
    "    for _ in range(sequence_length):\n",
    "        prediction = model.predict(generated_sequence[-30:].reshape(1, -1, 20))  # Reshape to (1, 30, 20)\n",
    "        generated_sequence = np.vstack([generated_sequence, prediction])\n",
    "        \n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182015aa-89b4-4761-a122-fa0de88b285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_to_audio(mfcc_sequence, sr=22050):\n",
    "    S = librosa.feature.inverse.mfcc_to_mel(mfcc_sequence.T, n_mels=128)\n",
    "    audio = librosa.feature.inverse.mel_to_audio(S, sr=sr)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f187e-63f7-4c4e-898f-55657f962f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "# Load a seed audio file and extract initial MFCCs\n",
    "y, sr = librosa.load(os.path.join(major_folder, \"Major_8.wav\"))  # replace with actual file path\n",
    "initial_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T[:sequence_length]  # First sequence\n",
    "\n",
    "# Generating  melody\n",
    "generated_mfccs = generate_sequence(model, initial_mfccs, sequence_length=100)  # Generate 100 frames\n",
    "\n",
    "# Convert generated MFCCs to audio\n",
    "generated_audio = mfcc_to_audio(generated_mfccs, sr=sr)\n",
    "\n",
    "# Play generated audio\n",
    "ipd.Audio(generated_audio, rate=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906aeff1-8f74-44ff-b88a-365bf0284a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "# Load a seed audio file and extract initial MFCCs\n",
    "y, sr = librosa.load(os.path.join(minor_folder, \"Minor_8.wav\"))  # replace with actual file path\n",
    "initial_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T[:sequence_length]  # First sequence\n",
    "\n",
    "# Generate a melody\n",
    "generated_mfccs = generate_sequence(model, initial_mfccs, sequence_length=100)  # Generate 100 frames\n",
    "\n",
    "# Convert generated MFCCs to audio\n",
    "generated_audio = mfcc_to_audio(generated_mfccs, sr=sr)\n",
    "\n",
    "# Play generated audio\n",
    "ipd.Audio(generated_audio, rate=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f959653-2591-4fe7-bc7a-04000fd44a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate a sequence with added Gaussian noise\n",
    "def generate_sequence_with_noise(model, start_sequence, sequence_length, noise_stddev=0.01):\n",
    "    generated_sequence = start_sequence.copy()\n",
    "    \n",
    "    for _ in range(sequence_length):\n",
    "        # Predict the next MFCC frame\n",
    "        prediction = model.predict(generated_sequence[-30:].reshape(1, -1, n_mfcc)).flatten()\n",
    "        \n",
    "        # Add Gaussian noise to the prediction for variability\n",
    "        prediction += np.random.normal(0, noise_stddev, prediction.shape)\n",
    "        \n",
    "        # Append the predicted frame to the generated sequence\n",
    "        generated_sequence = np.vstack([generated_sequence, prediction])\n",
    "        \n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert MFCC back to audio\n",
    "def mfcc_to_audio(mfcc_sequence, sr=22050):\n",
    "    S = librosa.feature.inverse.mfcc_to_mel(mfcc_sequence.T, n_mels=128)\n",
    "    audio = librosa.feature.inverse.mel_to_audio(S, sr=sr)\n",
    "    return audio\n",
    "\n",
    "# Load a seed audio file and extract MFCCs\n",
    "y, sr = librosa.load(os.path.join(major_folder, \"Major_9.wav\"))  # replace with actual file path\n",
    "initial_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).T[:sequence_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c68b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the melody with Gaussian noise added\n",
    "generated_mfccs = generate_sequence_with_noise(model, initial_mfccs, sequence_length=100, noise_stddev=0.01)\n",
    "\n",
    "# Convert generated MFCCs to audio\n",
    "generated_audio = mfcc_to_audio(generated_mfccs, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrogram of the generated audio\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.waveshow(generated_audio, sr=sr)\n",
    "plt.title(\"Generated Audio Waveform\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "librosa.display.waveshow(y = y, sr = sr)\n",
    "plt.title(\"Original Audio Waveform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecce8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the generated audio\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(generated_audio, rate=sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
